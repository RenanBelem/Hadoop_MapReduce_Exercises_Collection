# Hadoop MapReduce Exercises Collection

Este reposit√≥rio cont√©m uma cole√ß√£o de exerc√≠cios pr√°ticos de **Hadoop MapReduce** desenvolvidos em Java. O projeto est√° dividido em n√≠veis de complexidade, variando de contagens simples de palavras (WordCount) a cadeias de Jobs (Chain Mapper/Reducer) e implementa√ß√£o de serializa√ß√£o customizada (`Custom Writables`) para manipula√ß√£o de dados complexos.

## üìÇ Estrutura do Projeto

O c√≥digo est√° organizado em dois pacotes principais:

  * **`basic`**: Cont√©m as classes `Driver` (com `main`), `Mapper` e `Reducer` para resolu√ß√£o de problemas de neg√≥cios baseados em transa√ß√µes comerciais (Commodities).
  * **`advanced`**:
      * **`entropy`**: Cont√©m um algoritmo espec√≠fico para c√°lculo de Entropia de Shannon em sequ√™ncias gen√©ticas (FASTA).
      * **`customwritable`**: Cont√©m classes que implementam a interface `Writable` e `WritableComparable` do Hadoop. **Nota:** Estas classes servem de base tanto para os exerc√≠cios avan√ßados quanto para os exerc√≠cios da pasta `basic`.

-----

## üìä Datasets Utilizados

Os exerc√≠cios foram projetados para processar os seguintes tipos de arquivos (localizados na pasta `in/`):

1.  **`transactions_amostra.csv`**: Dados de com√©rcio exterior (Exporta√ß√£o/Importa√ß√£o) contendo: `country`, `year`, `comm_code`, `commodity`, `flow`, `trade_usd`, `weight_kg`, `quantity_name`, `category`.
2.  **`*.fasta`**: Sequ√™ncias de DNA para an√°lise de entropia.
3.  **`bible.txt`** ou textos gerais: Para testes simples de WordCount.
4.  **Forest Fire / Weather Data**: Para o exerc√≠cio de temperatura m√©dia.

-----

## üöÄ Lista de Exerc√≠cios e Funcionalidades

### 1\. Pacote Basic (An√°lise de Commodities)

Estes exerc√≠cios focam na an√°lise do dataset de transa√ß√µes. Alguns utilizam classes auxiliares do pacote `advanced.customwritable`.

| Classe | Descri√ß√£o do Problema | Complexidade | Conceitos Chave |
| :--- | :--- | :--- | :--- |
| `Exercicio1` | Contar n√∫mero de transa√ß√µes envolvendo o "Brazil". | F√°cil | Filtro simples (`if`), Count. |
| `Exercicio2` | N√∫mero de transa√ß√µes por **Tipo de Fluxo** e **Ano**. | F√°cil | Chave Composta (`TipoAnoWritable`). |
| `Exercicio3` | M√©dia dos valores das commodities por **Ano**. | F√°cil | Agrega√ß√£o, `ComdAnoValorWritable`. |
| `Exercicio4` | Pre√ßo m√©dio por Unidade, Ano e Categoria (Brasil/Export). | F√°cil | Filtros m√∫ltiplos, Chave complexa (`GroupTipoUnidadeWritable`). |
| `Exercicio5` | Pre√ßo M√°ximo, M√≠nimo e M√©dio por Unidade e Ano. | M√©dio | Objeto de valor complexo (`MaxMinMediaWritable`), L√≥gica Min/Max no Reducer. |
| `Exercicio6` | Pa√≠s com o maior pre√ßo m√©dio de commodity (Exporta√ß√£o). | Dif√≠cil | **Job Chaining** (2 Jobs). O 1¬∫ calcula m√©dias, o 2¬∫ encontra o m√°ximo global. |
| `Exercicio7` | Commodity mais comercializada em 2016 por fluxo. | Dif√≠cil | **Job Chaining**. O 1¬∫ soma quantidades, o 2¬∫ compara totais por fluxo. |
| `Teste` | Prova de conceito simples. | Intro | MapReduce "Hello World". |
| `WordCount` | Esqueleto cl√°ssico de contagem de palavras. | Intro | Template base. |

### 2\. Pacote Advanced (Entropia e Customiza√ß√£o)

Focado em serializa√ß√£o eficiente e algoritmos cient√≠ficos.

  * **`EntropyFASTA.java`**: Calcula a Entropia de Shannon de uma sequ√™ncia de DNA.
      * *Etapa 1:* Conta a frequ√™ncia de cada base (A, C, T, G) e o total.
      * *Etapa 2:* Calcula $H(X) = - \sum P(x) \log_2 P(x)$.
  * **`AverageTemperature.java`**: Calcula temperatura m√©dia utilizando `FireAvgTempWritable` para trafegar somas parciais e contadores do Map para o Reduce.

### 3\. Classes Writable Customizadas (`advanced.customwritable`)

Estas classes permitem que o Hadoop trafegue objetos complexos pela rede e realize ordena√ß√µes compostas.

  * **Chaves Compostas (Implementam `WritableComparable`):**
      * `TipoAnoWritable`: (Ano, Fluxo)
      * `GroupTipoUnidadeWritable`: (Ano, Commodity, Unidade, Categoria)
      * `ComdAnoValorWritable`: (Commodity, Ano)
      * `GroupMaxMinMedia`: (Ano, Unidade)
      * `PaisMediaWritable`, `ComdTipoFluxoWritable`, etc.
  * **Valores Complexos (Implementam `Writable`):**
      * `MaxMinMediaWritable`: Armazena (N, Soma, Max, Min).
      * `TipoUnidadeWritable`: Armazena (N, Pre√ßo).
      * `FireAvgTempWritable`: Armazena (SomaTemperaturas, Qtd).

-----

## üõ†Ô∏è Como Compilar e Executar

Certifique-se de ter o Hadoop instalado e configurado.

1.  **Compila√ß√£o:**

    ```bash
    # Crie uma pasta para as classes compiladas
    mkdir -p classes

    # Compile o c√≥digo (ajuste o classpath conforme sua instala√ß√£o do Hadoop)
    javac -cp $(hadoop classpath) -d classes src/basic/*.java src/advanced/customwritable/*.java src/advanced/entropy/*.java
    ```

2.  **Empacotamento (.jar):**

    ```bash
    jar -cvf mapreduce-exercises.jar -C classes/ .
    ```

3.  **Execu√ß√£o:**
    Exemplo para rodar o **Exercicio 4**:

    ```bash
    # Limpe a sa√≠da anterior se existir
    hdfs dfs -rm -r output/ex4.txt

    # Execute o Job
    hadoop jar mapreduce-exercises.jar basic.Exercicio4
    ```

    Exemplo para rodar o **EntropyFASTA** (requer argumentos de entrada/sa√≠da):

    ```bash
    hadoop jar mapreduce-exercises.jar advanced.entropy.EntropyFASTA in/amostra.fasta output/entropia_result
    ```

-----

## üìù Notas de Implementa√ß√£o

  * **Job Chaining (Exerc√≠cios 6 e 7):** Estes exerc√≠cios utilizam arquivos tempor√°rios (`intermediate.tmp`) para passar o resultado do primeiro MapReduce para o segundo. O c√≥digo gerencia caminhos intermedi√°rios automaticamente.
  * **Combiners:** V√°rios exerc√≠cios (`Exercicio1`, `Exercicio2`, `AverageTemperature`, etc.) implementam *Combiners* para otimizar a largura de banda da rede, realizando pr√©-agrega√ß√µes locais antes do envio ao Reducer.
